import pandas as pd
from pyformlang.regular_expression import Regex
from pyformlang.finite_automaton import DeterministicFiniteAutomaton
import re
import rstr
import logging
import Levenshtein  # éœ€è¦å®‰è£… python-Levenshtein åº“
import os


# é…ç½®æ—¥å¿—è®°å½•
def setup_logging(log_file):
    """
    è®¾ç½®æ—¥å¿—è®°å½•å™¨ã€‚
    """
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file),  # å°†æ—¥å¿—å†™å…¥æ–‡ä»¶
            logging.StreamHandler()         # åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°
        ]
    )


# æ­£åˆ™è¡¨è¾¾å¼æ ‡å‡†åŒ–
def normalize_regex(regex_str):
    """
    æ ‡å‡†åŒ–æ­£åˆ™è¡¨è¾¾å¼ã€‚
    """
    if not isinstance(regex_str, str) or not regex_str.strip():
        return regex_str  # å¦‚æœæ˜¯ç©ºå€¼æˆ–éå­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›åŸå€¼

    # 1. å¤„ç†å­—ç¬¦ç±»
    regex_str = regex_str.replace('[0-9]', '\\d')          # [0-9] -> \d
    regex_str = regex_str.replace('[a-zA-Z]', '[A-Za-z]')  # [a-zA-Z] -> [A-Za-z]
    regex_str = regex_str.replace('[^0-9]', '\\D')         # [^0-9] -> \D
    regex_str = regex_str.replace('[^a-zA-Z]', '[^A-Za-z]')# [^a-zA-Z] -> [^A-Za-z]
    regex_str = regex_str.replace('[ \t\n\r\f\v]', '\\s')  # [ \t\n\r\f\v] -> \s
    regex_str = regex_str.replace('[^ \t\n\r\f\v]', '\\S') # [^ \t\n\r\f\v] -> \S

    # 2. å¤„ç†é‡è¯
    regex_str = re.sub(r'\{1\}', '', regex_str)            # {1} -> ç©º
    regex_str = re.sub(r'\{1,1\}', '', regex_str)          # {1,1} -> ç©º

    # 3. å»é™¤å¤šä½™çš„è½¬ä¹‰å­—ç¬¦
    regex_str = regex_str.replace('\\\\d', '\\d')
    regex_str = regex_str.replace('\\\\w', '\\w')

    # 4. ç»Ÿä¸€æ‹¬å·å’Œåˆ†ç»„çš„å†™æ³•
    # å°† (?:...) æ›¿æ¢ä¸º (...)ï¼Œé™¤éæ˜ç¡®éœ€è¦éæ•è·åˆ†ç»„
    regex_str = regex_str.replace('(?:', '(')
    regex_str = regex_str.replace(')', ')')

    # 5. å…¶ä»–ä¼˜åŒ–
    # ç§»é™¤å¤šä½™çš„ç©ºæ ¼
    regex_str = regex_str.replace(' ', '')

    return regex_str


# ç”Ÿæˆä¸€ä¸ªç”¨äºæµ‹è¯•çš„å­—ç¬¦ä¸²åˆ—è¡¨
def generate_test_strings():
    """ç”Ÿæˆä¸€ä¸ªç”¨äºæµ‹è¯•çš„å­—ç¬¦ä¸²åˆ—è¡¨"""
    return [
        '',          # ç©ºå­—ç¬¦ä¸²
        '0',         # å•ä¸ªæ•°å­—
        '1',         # å•ä¸ªæ•°å­—
        'a',         # å•ä¸ªå­—æ¯
        '!',         # ç‰¹æ®Šå­—ç¬¦
        '12',        # ä¸¤ä¸ªæ•°å­—
        'ab',        # ä¸¤ä¸ªå­—æ¯
        'abc123',    # å­—æ¯å’Œæ•°å­—ç»„åˆ
        'special@char!',  # åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„å­—ç¬¦ä¸²
        ' ' * 10,    # å¤šä¸ªç©ºæ ¼
        '1' * 10,    # å¤šä¸ªç›¸åŒæ•°å­—
        'hello!world',  # å¸¸è§å­—ç¬¦ä¸²
        '\t',        # åˆ¶è¡¨ç¬¦
        '\n',        # æ¢è¡Œç¬¦
        'ğŸ˜Š',        # è¡¨æƒ…ç¬¦å·
    ]


# å®šä¹‰ä¸€ä¸ªå‡½æ•°å°†æ­£åˆ™è¡¨è¾¾å¼è½¬æ¢ä¸ºæœ€å°åŒ–çš„DFA
def regex_to_min_dfa(regex_str):
    try:
        # å¯¹éƒ¨åˆ†ç‰¹æ®Šå­—ç¬¦è¿›è¡Œè½¬ä¹‰ï¼Œé¿å…ç ´åæ­£åˆ™è¡¨è¾¾å¼çš„è¯­ä¹‰
        regex_str = (
            regex_str
            .replace('(', '$')  # è½¬ä¹‰å·¦æ‹¬å·
            .replace(')', '$')  # è½¬ä¹‰å³æ‹¬å·
            .replace('.', '\.')  # è½¬ä¹‰ç‚¹å·
            .replace('*', '\*')  # è½¬ä¹‰æ˜Ÿå·
            .replace('+', '\+')  # è½¬ä¹‰åŠ å·
            .replace('?', '\?')  # è½¬ä¹‰é—®å·
        )

        # åˆ›å»ºæ­£åˆ™è¡¨è¾¾å¼å¯¹è±¡
        regex = Regex(regex_str)
        # è½¬æ¢ä¸ºæœ€å°åŒ–çš„DFA
        min_dfa = regex.to_epsilon_nfa().to_deterministic().minimize()
        return min_dfa
    except Exception as e:
        logging.error(f"æ— æ³•è§£ææ­£åˆ™è¡¨è¾¾å¼ '{regex_str}'ï¼Œé”™è¯¯: {e}")
        return None


# ä½¿ç”¨ rstr åº“ç”Ÿæˆéšæœºå­—ç¬¦ä¸²å¹¶æ¯”è¾ƒä¸¤ä¸ªæ­£åˆ™è¡¨è¾¾å¼çš„ç­‰ä»·æ€§
def are_regex_equivalent_by_rstr(regex1, regex2, num_samples=100):
    try:
        # ä½¿ç”¨ rstr ç”Ÿæˆéšæœºå­—ç¬¦ä¸²
        samples1 = set(rstr.xeger(regex1) for _ in range(num_samples))
        samples2 = set(rstr.xeger(regex2) for _ in range(num_samples))

        logging.info(f"Regex1 ({regex1}) ç”Ÿæˆçš„å­—ç¬¦ä¸²: {samples1}")
        logging.info(f"Regex2 ({regex2}) ç”Ÿæˆçš„å­—ç¬¦ä¸²: {samples2}")

        # æ¯”è¾ƒä¸¤ä¸ªé›†åˆæ˜¯å¦ç›¸ç­‰
        return samples1 == samples2
    except Exception as e:
        logging.error(f"æ— æ³•ç”Ÿæˆéšæœºå­—ç¬¦ä¸²ï¼Œé”™è¯¯: {e}")
        return False


# ä½¿ç”¨æµ‹è¯•å­—ç¬¦ä¸²é›†æ¯”è¾ƒä¸¤ä¸ªæ­£åˆ™è¡¨è¾¾å¼çš„ç­‰ä»·æ€§
def are_regex_equivalent_by_tests(regex1, regex2, test_strings):
    matches1 = [bool(re.match(regex1, s)) for s in test_strings]
    matches2 = [bool(re.match(regex2, s)) for s in test_strings]

    return matches1 == matches2


# å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¯”è¾ƒä¸¤ä¸ªæ­£åˆ™è¡¨è¾¾å¼æ˜¯å¦ç­‰ä»·
def are_regex_equivalent(regex1, regex2, log_details=False):
    # æ ‡å‡†åŒ–æ­£åˆ™è¡¨è¾¾å¼
    regex1 = normalize_regex(regex1)
    regex2 = normalize_regex(regex2)

    dfa1 = regex_to_min_dfa(regex1)
    dfa2 = regex_to_min_dfa(regex2)

    if dfa1 is not None and dfa2 is not None:
        # å¦‚æœä¸¤ä¸ªæ­£åˆ™è¡¨è¾¾å¼éƒ½èƒ½æˆåŠŸè§£æä¸º DFAï¼Œåˆ™ç›´æ¥æ¯”è¾ƒ
        is_equivalent = dfa1.is_equivalent_to(dfa2)
        if log_details:
            logging.info(f"DFA æ¯”è¾ƒç»“æœï¼š'{regex1}' å’Œ '{regex2}' {'ç­‰ä»·' if is_equivalent else 'ä¸ç­‰ä»·'}")
        return is_equivalent

    # å¦‚æœæ— æ³•è§£æä¸º DFAï¼Œåˆ™å°è¯•ä½¿ç”¨ rstr ç”Ÿæˆéšæœºå­—ç¬¦ä¸²è¿›è¡Œæ¯”è¾ƒ
    if are_regex_equivalent_by_rstr(regex1, regex2):
        return True

    # æœ€åå›é€€åˆ°æµ‹è¯•å­—ç¬¦ä¸²é›†
    test_strings = generate_test_strings()
    is_equivalent = are_regex_equivalent_by_tests(regex1, regex2, test_strings)
    if log_details:
        logging.info(f"æµ‹è¯•å­—ç¬¦ä¸²é›†æ¯”è¾ƒç»“æœï¼š'{regex1}' å’Œ '{regex2}' {'ç­‰ä»·' if is_equivalent else 'ä¸ç­‰ä»·'}")
    return is_equivalent


# è®¡ç®—ç¼–è¾‘è·ç¦»å¹¶å½’ä¸€åŒ–ä¸ºç›¸ä¼¼åº¦åˆ†æ•°
def calculate_similarity(regex1, regex2):
    edit_distance = Levenshtein.distance(regex1, regex2)
    max_length = max(len(regex1), len(regex2))
    normalized_edit_distance = edit_distance / max_length if max_length > 0 else 0
    similarity_score = 1 - normalized_edit_distance
    return similarity_score


# ä¸»ç¨‹åº
if __name__ == "__main__":
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs("./part_logs", exist_ok=True)

    # é…ç½®æ—¥å¿—æ–‡ä»¶
    log_file = "./part_logs/regex_comparison.log"
    setup_logging(log_file)

    # è¯»å–Excelæ–‡ä»¶
    file_path = "./data/output_with_final_regex.xlsx"
    df = pd.read_excel(file_path)

    # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„åˆ—
    if df.shape[1] < 4:
        raise ValueError("Excelæ–‡ä»¶ä¸­åˆ—æ•°ä¸è¶³ï¼Œè¯·ç¡®ä¿è‡³å°‘æœ‰4åˆ—ã€‚")

    # åˆå§‹åŒ–ç»Ÿè®¡å˜é‡
    total_rows = len(df)
    equivalent_count = 0
    partial_match_count = 0
    results = []

    # éå†æ¯ä¸€è¡Œå¹¶æ¯”è¾ƒç¬¬äºŒåˆ—å’Œç¬¬å››åˆ—çš„æ­£åˆ™è¡¨è¾¾å¼
    for index, row in df.iterrows():
        regex_col2 = row.iloc[1]  # ç¬¬äºŒåˆ—
        regex_col4 = row.iloc[3]  # ç¬¬å››åˆ—

        if pd.isna(regex_col2) or pd.isna(regex_col4):
            logging.warning(f"ç¬¬ {index + 1} è¡Œæœ‰ç©ºå€¼ï¼Œè·³è¿‡æ¯”è¾ƒã€‚")
            continue

        # æ¯”è¾ƒä¸¤ä¸ªæ­£åˆ™è¡¨è¾¾å¼æ˜¯å¦ç­‰ä»·
        is_equivalent = are_regex_equivalent(regex_col2, regex_col4, log_details=True)
        if is_equivalent:
            equivalent_count += 1

        # è®¡ç®—ç¼–è¾‘è·ç¦»ç›¸ä¼¼åº¦åˆ†æ•°
        similarity_score = calculate_similarity(regex_col2, regex_col4)
        if similarity_score >= 0.8:  # è®¾å®šéƒ¨åˆ†åŒ¹é…çš„é˜ˆå€¼ä¸º 0.8
            partial_match_count += 1

        # è®°å½•æ¯è¡Œçš„ç»“æœ
        results.append({
            "Row": index + 1,
            "Regex1": regex_col2,
            "Regex2": regex_col4,
            "IsEquivalent": is_equivalent,
            "SimilarityScore": similarity_score
        })

    # è®¡ç®—ç­‰ä»·æ¯”ä¾‹å’Œéƒ¨åˆ†åŒ¹é…ç‡
    equivalence_ratio = equivalent_count / total_rows
    partial_match_ratio = partial_match_count / total_rows
    logging.info(f"\næ€»è¡Œæ•°: {total_rows}")
    logging.info(f"ç­‰ä»·è¡Œæ•°: {equivalent_count}")
    logging.info(f"ç­‰ä»·æ¯”ä¾‹: {equivalence_ratio:.2%}")
    logging.info(f"éƒ¨åˆ†åŒ¹é…è¡Œæ•°: {partial_match_count}")
    logging.info(f"éƒ¨åˆ†åŒ¹é…ç‡: {partial_match_ratio:.2%}")

    # å°†ç»“æœä¿å­˜åˆ° CSV æ–‡ä»¶
    results_df = pd.DataFrame(results)
    results_df.to_csv("./part_logs/regex_comparison_results.csv", index=False)
    logging.info("ç»“æœå·²ä¿å­˜åˆ° './part_logs/regex_comparison_results.csv'")