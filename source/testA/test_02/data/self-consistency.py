import pandas as pd
import re
from collections import defaultdict
import random
import logging
from pyformlang.regular_expression import Regex
from pyformlang.finite_automaton import DeterministicFiniteAutomaton

# è®¾ç½®æ—¥å¿—è®°å½•
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("self_consistency_processing.log"),
        logging.StreamHandler()
    ]
)

# =============== æ­£åˆ™è¡¨è¾¾å¼æ ‡å‡†åŒ– & ç­‰ä»·æ€§åˆ¤æ–­å‡½æ•° ===============
def normalize_regex(regex_str):
    if not isinstance(regex_str, str) or not regex_str.strip():
        return regex_str

    # æ ‡å‡†åŒ–å­—ç¬¦ç±»
    regex_str = regex_str.replace('[0-9]', '\\d')
    regex_str = regex_str.replace('[a-zA-Z]', '[A-Za-z]')
    regex_str = regex_str.replace('[^0-9]', '\\D')
    regex_str = regex_str.replace('[^a-zA-Z]', '[^A-Za-z]')
    regex_str = regex_str.replace('[ \t\n\r\f\v]', '\\s')
    regex_str = regex_str.replace('[^ \t\n\r\f\v]', '\\S')

    # å¤„ç†é‡è¯
    regex_str = re.sub(r'\{1\}', '', regex_str)
    regex_str = re.sub(r'\{1,1\}', '', regex_str)
    regex_str = regex_str.replace('{1,}', '+')

    # å»é™¤å¤šä½™è½¬ä¹‰
    regex_str = regex_str.replace('\\\\d', '\\d').replace('\\\\w', '\\w')

    # ç»Ÿä¸€æ‹¬å·å†™æ³•
    regex_str = regex_str.replace('(?:', '(').replace(')', ')')

    # ç§»é™¤è¾¹ç•Œç¬¦å·
    if regex_str.startswith('^'):
        regex_str = regex_str[1:]
    if regex_str.endswith('$'):
        regex_str = regex_str[:-1]

    # å»é™¤ç©ºæ ¼
    regex_str = regex_str.replace(' ', '')

    return regex_str


def are_regex_equivalent(regex1, regex2):
    try:
        r1 = Regex(normalize_regex(regex1))
        r2 = Regex(normalize_regex(regex2))

        dfa1 = r1.to_epsilon_nfa().to_deterministic().minimize()
        dfa2 = r2.to_epsilon_nfa().to_deterministic().minimize()

        return dfa1.is_equivalent_to(dfa2)

    except Exception as e:
        logging.warning(f"æ— æ³•å°†æ­£åˆ™è¡¨è¾¾å¼è½¬æ¢ä¸º DFA è¿›è¡Œæ¯”è¾ƒ: {e}")
        test_strings = [
            '', '0', '1', 'a', '!', '12', 'ab', 'abc123', 'special@char!', ' ' * 10,
            '1' * 10, 'hello!world', '\t', '\n', 'ğŸ˜Š'
        ]
        matches1 = [bool(re.fullmatch(regex1, s)) for s in test_strings]
        matches2 = [bool(re.fullmatch(regex2, s)) for s in test_strings]
        return matches1 == matches2


# =============== æå–æœ€ç»ˆæ­£åˆ™è¡¨è¾¾å¼ ===============
def extract_final_regex(chain_of_thought):
    if pd.isna(chain_of_thought):
        return None

    lines = chain_of_thought.strip().split('\n')
    last_line = lines[-1].strip()

    match = re.search(r'æ­£åˆ™è¡¨è¾¾å¼ï¼š(.*)', last_line)
    if match:
        return match.group(1).strip()
    return None


# =============== å°†ç­‰ä»·çš„æ­£åˆ™è¡¨è¾¾å¼å½’ç±» ===============
def cluster_equivalent_regex(regex_list):
    clusters = []

    for regex in regex_list:
        matched = False
        for cluster in clusters:
            if are_regex_equivalent(regex, cluster[0]):
                cluster.append(regex)
                matched = True
                break
        if not matched:
            clusters.append([regex])
    return clusters


# =============== Self-Consistency by Equivalence Class ===============
def self_consistency_by_equivalence_class(regex_list):
    if not regex_list:
        return None

    clusters = cluster_equivalent_regex(regex_list)

    largest_cluster = max(clusters, key=len)
    logging.info(f"æ‰¾åˆ°çš„æœ€å¤§ç±»åˆ«å¤§å°ä¸º: {len(largest_cluster)}")
    logging.info(f"è¯¥ç±»åˆ«ä¸­çš„æ­£åˆ™è¡¨è¾¾å¼: {largest_cluster}")

    return random.choice(largest_cluster)


# =============== ä¸»å¤„ç†å‡½æ•° ===============
def process_rows_with_self_consistency(df):
    df['æœ€ç»ˆæ­£åˆ™è¡¨è¾¾å¼'] = None

    total_rows = len(df)
    success_count = 0

    for index, row in df.iterrows():
        regex_list = []

        for col_idx in range(2, 7):  # ç¬¬ 3 åˆ°ç¬¬ 7 åˆ—
            chain_of_thought = row.iloc[col_idx]
            regex = extract_final_regex(chain_of_thought)
            if regex:
                regex_list.append(regex)

        if not regex_list:
            logging.warning(f"ç¬¬ {index + 1} è¡Œæ²¡æœ‰æœ‰æ•ˆçš„æ­£åˆ™è¡¨è¾¾å¼ï¼Œè·³è¿‡ã€‚")
            continue

        final_regex = self_consistency_by_equivalence_class(regex_list)
        df.at[index, 'æœ€ç»ˆæ­£åˆ™è¡¨è¾¾å¼'] = final_regex
        success_count += 1

        logging.info(f"ç¬¬ {index + 1} è¡Œå¤„ç†å®Œæˆï¼Œæœ€ç»ˆæ­£åˆ™è¡¨è¾¾å¼: {final_regex}")

    logging.info("\n================== Self-Consistency å®Œæˆ ==================")
    logging.info(f"æ€»å¤„ç†è¡Œæ•°: {success_count}/{total_rows}")

    return df


# =============== ä¸»ç¨‹åºå…¥å£ ===============
if __name__ == "__main__":
    file_path = 'output_with_chain_of_thought.xlsx'
    df = pd.read_excel(file_path)

    df_processed = process_rows_with_self_consistency(df)

    new_file_path = 'output_with_final_regex_self_consistency.xlsx'
    df_processed.to_excel(new_file_path, index=False)

    logging.info(f"å¤„ç†å®Œæˆï¼Œå·²å°†æœ€ç»ˆæ­£åˆ™è¡¨è¾¾å¼ä¿å­˜åˆ°æ–°æ–‡ä»¶ï¼š{new_file_path}")